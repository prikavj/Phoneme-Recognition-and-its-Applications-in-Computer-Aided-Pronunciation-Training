{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"# TensorFlow and Keras Imports\nimport tensorflow as tf\nfrom tensorflow.keras import regularizers as rg\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, TimeDistributed\n\n# Garbage Collection and Pickle Imports\nimport gc\nimport pickle as pkl\n\n# Visualization and Data Handling Imports\nimport matplotlib.pyplot as plt\nimport os\nimport numpy as np\nimport pandas as pd\n\n# Scikit-learn Import\nfrom sklearn.model_selection import train_test_split\n\n# JSON Import\nimport json\n\n# Time-related Import\nimport time","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-28T19:58:35.668867Z","iopub.execute_input":"2023-07-28T19:58:35.669150Z","iopub.status.idle":"2023-07-28T19:58:52.373474Z","shell.execute_reply.started":"2023-07-28T19:58:35.669123Z","shell.execute_reply":"2023-07-28T19:58:52.372431Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Load Training Data","metadata":{}},{"cell_type":"code","source":"features_path = \"/kaggle/input/timitpreprocessed/features.pkl\"\nlabels_path = \"/kaggle/input/timitpreprocessed/labels.pkl\"\n\nwith open(features_path, 'rb') as pickle_file:\n    features = pkl.load(pickle_file)\n    \nwith open(labels_path, 'rb') as pickle_file:\n    labels = pkl.load(pickle_file)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T19:58:52.375381Z","iopub.execute_input":"2023-07-28T19:58:52.376491Z","iopub.status.idle":"2023-07-28T19:59:08.498173Z","shell.execute_reply.started":"2023-07-28T19:58:52.376443Z","shell.execute_reply":"2023-07-28T19:59:08.497157Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Load Testing Data","metadata":{}},{"cell_type":"code","source":"test_features_path = \"/kaggle/input/timitpreprocessed/test_features.pkl\"\ntest_labels_path = \"/kaggle/input/timitpreprocessed/test_labels.pkl\"\n\nwith open(test_features_path, 'rb') as pickle_file:\n    test_features = pkl.load(pickle_file)\n    \nwith open(test_labels_path, 'rb') as pickle_file:\n    test_labels = pkl.load(pickle_file)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T19:59:08.499636Z","iopub.execute_input":"2023-07-28T19:59:08.500015Z","iopub.status.idle":"2023-07-28T19:59:14.242305Z","shell.execute_reply.started":"2023-07-28T19:59:08.499979Z","shell.execute_reply":"2023-07-28T19:59:14.241303Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Create mapping functions for Phonemes","metadata":{}},{"cell_type":"code","source":"map_phonemes_61_to_39 = {\n            'iy':'iy',  'ih':'ih',   'eh':'eh',  'ae':'ae',    'ix':'ih',  'ax':'ah',   'ah':'ah',  'uw':'uw',\n            'ux':'uw',  'uh':'uh',   'ao':'aa',  'aa':'aa',    'ey':'ey',  'ay':'ay',   'oy':'oy',  'aw':'aw',\n            'ow':'ow',  'l':'l',     'el':'l',  'r':'r',      'y':'y',    'w':'w',     'er':'er',  'axr':'er',\n            'm':'m',    'em':'m',     'n':'n',    'nx':'n',     'en':'n',  'ng':'ng',   'eng':'ng', 'ch':'ch',\n            'jh':'jh',  'dh':'dh',   'b':'b',    'd':'d',      'dx':'dx',  'g':'g',     'p':'p',    't':'t',\n            'k':'k',    'z':'z',     'zh':'sh',  'v':'v',      'f':'f',    'th':'th',   's':'s',    'sh':'sh',\n            'hh':'hh',  'hv':'hh',   'pcl':'h#', 'tcl':'h#', 'kcl':'h#', 'qcl':'h#','bcl':'h#','dcl':'h#',\n            'gcl':'h#','h#':'h#',  '#h':'h#',  'pau':'h#', 'epi': 'h#','nx':'n',   'ax-h':'ah','q':'h#' \n        }\n\nphonemes_list_61 = list(map_phonemes_61_to_39.keys())\nphonemes_list_39 = list(set(map_phonemes_61_to_39.values()))\n\nlabel_to_phoneme39 = {}\nphoneme39_to_label = {}\nfor index,phoneme in enumerate(phonemes_list_39):\n    label_to_phoneme39[phoneme] = index + 1\n    phoneme39_to_label[index + 1] = phoneme\n\nmap_phonemes_39_to_61 = {}\n\nfor phoneme61,phoneme39 in map_phonemes_61_to_39.items():\n    if not phoneme39 in map_phonemes_39_to_61:\n        map_phonemes_39_to_61[phoneme39] = []\n    map_phonemes_39_to_61[phoneme39].append(phoneme61)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T19:59:14.244798Z","iopub.execute_input":"2023-07-28T19:59:14.245145Z","iopub.status.idle":"2023-07-28T19:59:14.258360Z","shell.execute_reply.started":"2023-07-28T19:59:14.245112Z","shell.execute_reply":"2023-07-28T19:59:14.257257Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Build LSTM Model","metadata":{}},{"cell_type":"code","source":"\n\ndef build_model(input_dim, output_dim, rnn_layers=5, rnn_units=128):\n    model = tf.keras.Sequential()\n\n    model.add(LSTM(1000, input_shape=(None, input_dim), return_sequences=True))\n    model.add(LSTM(1000, return_sequences=True))\n    model.add(LSTM(1000, return_sequences=True))\n    model.add(TimeDistributed(Dense(output_dim, activation='softmax')))\n    # Optimizer\n    opt = keras.optimizers.Adam(learning_rate=1e-4)\n    # Compile the model and return\n    model.compile(optimizer=opt, loss='categorical_crossentropy', run_eagerly=True, metrics=['accuracy'])\n    return model\n\nn_mels = 64\nfft_length =  384\n# Get the model\nmodel = build_model(\n    input_dim= n_mels*3,\n    output_dim=len(phoneme39_to_label),\n    rnn_units=512,\n)\nmodel.summary(line_length=110)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T19:59:14.259823Z","iopub.execute_input":"2023-07-28T19:59:14.260133Z","iopub.status.idle":"2023-07-28T19:59:23.752621Z","shell.execute_reply.started":"2023-07-28T19:59:14.260102Z","shell.execute_reply":"2023-07-28T19:59:23.751782Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n______________________________________________________________________________________________________________\n Layer (type)                                    Output Shape                                Param #          \n==============================================================================================================\n lstm (LSTM)                                     (None, None, 1000)                          4772000          \n                                                                                                              \n lstm_1 (LSTM)                                   (None, None, 1000)                          8004000          \n                                                                                                              \n lstm_2 (LSTM)                                   (None, None, 1000)                          8004000          \n                                                                                                              \n time_distributed (TimeDistributed)              (None, None, 39)                            39039            \n                                                                                                              \n==============================================================================================================\nTotal params: 20,819,039\nTrainable params: 20,819,039\nNon-trainable params: 0\n______________________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Create callback class to computer Phoneme Error Rate","metadata":{}},{"cell_type":"code","source":"performance_rnn = {}\n\nimport numpy as np\nfrom tensorflow.keras.callbacks import Callback\nimport Levenshtein as lev\n\nclass PERCallback(Callback):\n    def __init__(self, X_val, y_val, phoneme_mapping):\n        self.X_val = X_val\n        self.X_val = self.X_val.reshape(self.X_val.shape[0], 1, self.X_val.shape[1])\n        self.y_val = y_val\n        self.phoneme_mapping = phoneme_mapping\n\n    def on_epoch_end(self, epoch, logs=None):\n        # Get the model predictions\n        predictions = self.model.predict(self.X_val)\n        \n        # Convert one-hot encoded vectors to phoneme sequences\n        reference_phonemes = [self.one_hot_to_phoneme(vec) for vec in self.y_val]\n        predicted_phonemes = [self.one_hot_to_phoneme(vec) for vec in predictions]\n\n        # Calculate PER\n        per = self.calculate_per(\" \".join(reference_phonemes), \" \".join(predicted_phonemes))\n        performance_rnn[epoch] = per\n        # Print PER\n        print(f'\\n Phoneme Error Rate after epoch {epoch}: {per}%')\n\n    def one_hot_to_phoneme(self, one_hot_vector):\n        index = np.argmax(one_hot_vector)\n        return self.phoneme_mapping.get(index-1, \"\")\n    \n    import Levenshtein as lev\n    \n    def calculate_per(self, reference, hypothesis):\n        distance = lev.distance(reference, hypothesis)\n        per = distance / len(reference)\n        return per * 100","metadata":{"execution":{"iopub.status.busy":"2023-07-28T19:59:23.754037Z","iopub.execute_input":"2023-07-28T19:59:23.754410Z","iopub.status.idle":"2023-07-28T19:59:23.904473Z","shell.execute_reply.started":"2023-07-28T19:59:23.754373Z","shell.execute_reply":"2023-07-28T19:59:23.903434Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def preprocess_features(features, labels):\n    # Map needs a fuction. The features are already preprocessed\n    return features, labels","metadata":{"execution":{"iopub.status.busy":"2023-07-28T19:59:23.905749Z","iopub.execute_input":"2023-07-28T19:59:23.906080Z","iopub.status.idle":"2023-07-28T19:59:23.911462Z","shell.execute_reply.started":"2023-07-28T19:59:23.906050Z","shell.execute_reply":"2023-07-28T19:59:23.910511Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Train the model","metadata":{}},{"cell_type":"code","source":"# Define the number of epochs.\nbatch_size = 128\n\n# This will split your data so that 70% is used for training and 30% for testing.\nX_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=0.3, random_state=42)\n\nX_train_reshaped = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\nX_val_reshaped = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n\ny_train_reshaped = y_train.reshape(y_train.shape[0], 1, y_train.shape[1])\ny_val_reshaped = y_val.reshape(y_val.shape[0], 1, y_val.shape[1])\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices(\n    (X_train_reshaped, y_train_reshaped)\n)\ntrain_dataset = (\n    train_dataset.map(preprocess_features, num_parallel_calls=tf.data.AUTOTUNE)\n    .padded_batch(batch_size)\n    .prefetch(buffer_size=tf.data.AUTOTUNE)\n)\n\nvalidation_dataset = tf.data.Dataset.from_tensor_slices(\n     (X_val_reshaped, y_val_reshaped)\n)\nvalidation_dataset = (\n    validation_dataset.map(preprocess_features, num_parallel_calls=tf.data.AUTOTUNE)\n    .padded_batch(batch_size)\n    .prefetch(buffer_size=tf.data.AUTOTUNE)\n)\n\nepochs = 10\n\n# Train the model\nstart_time = time.time()\n\nhistory = model.fit(\n    train_dataset,\n    validation_data=validation_dataset,\n    batch_size=batch_size,\n    epochs=epochs,\n    callbacks=[PERCallback(X_val, y_val, phoneme39_to_label)]\n)\n\nend_time = time.time()\n\n# Calculate the training time\ntraining_time = end_time - start_time\nprint(f\"Training time: {training_time:.2f} seconds\")","metadata":{"execution":{"iopub.status.busy":"2023-07-28T20:06:35.141216Z","iopub.execute_input":"2023-07-28T20:06:35.141606Z","iopub.status.idle":"2023-07-28T22:48:41.772241Z","shell.execute_reply.started":"2023-07-28T20:06:35.141574Z","shell.execute_reply":"2023-07-28T22:48:41.771228Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Epoch 1/10\n13329/13329 [==============================] - 289s 22ms/step\n\n Phoneme Error Rate after epoch 0: 30.428978611665958%\n7775/7775 [==============================] - 988s 127ms/step - loss: 1.6871 - accuracy: 0.5048 - val_loss: 1.6125 - val_accuracy: 0.5214\nEpoch 2/10\n13329/13329 [==============================] - 293s 22ms/step\n\n Phoneme Error Rate after epoch 1: 29.1427160715488%\n7775/7775 [==============================] - 992s 128ms/step - loss: 1.5427 - accuracy: 0.5389 - val_loss: 1.5176 - val_accuracy: 0.5439\nEpoch 3/10\n13329/13329 [==============================] - 292s 22ms/step\n\n Phoneme Error Rate after epoch 2: 28.143097605314544%\n7775/7775 [==============================] - 988s 127ms/step - loss: 1.4515 - accuracy: 0.5617 - val_loss: 1.4541 - val_accuracy: 0.5598\nEpoch 4/10\n13329/13329 [==============================] - 292s 22ms/step\n\n Phoneme Error Rate after epoch 3: 27.43649707116727%\n7775/7775 [==============================] - 962s 124ms/step - loss: 1.3872 - accuracy: 0.5779 - val_loss: 1.4101 - val_accuracy: 0.5709\nEpoch 5/10\n13329/13329 [==============================] - 280s 21ms/step\n\n Phoneme Error Rate after epoch 4: 26.718226092420945%\n7775/7775 [==============================] - 940s 121ms/step - loss: 1.3370 - accuracy: 0.5911 - val_loss: 1.3665 - val_accuracy: 0.5822\nEpoch 6/10\n13329/13329 [==============================] - 277s 21ms/step\n\n Phoneme Error Rate after epoch 5: 26.279148057544273%\n7775/7775 [==============================] - 947s 122ms/step - loss: 1.2944 - accuracy: 0.6026 - val_loss: 1.3408 - val_accuracy: 0.5891\nEpoch 7/10\n13329/13329 [==============================] - 277s 21ms/step\n\n Phoneme Error Rate after epoch 6: 25.86242341270732%\n7775/7775 [==============================] - 943s 121ms/step - loss: 1.2557 - accuracy: 0.6130 - val_loss: 1.3171 - val_accuracy: 0.5953\nEpoch 8/10\n13329/13329 [==============================] - 279s 21ms/step\n\n Phoneme Error Rate after epoch 7: 25.600107727180916%\n7775/7775 [==============================] - 905s 116ms/step - loss: 1.2199 - accuracy: 0.6229 - val_loss: 1.3012 - val_accuracy: 0.5993\nEpoch 9/10\n13329/13329 [==============================] - 277s 21ms/step\n\n Phoneme Error Rate after epoch 8: 25.41490674865902%\n7775/7775 [==============================] - 945s 122ms/step - loss: 1.1866 - accuracy: 0.6321 - val_loss: 1.2900 - val_accuracy: 0.6024\nEpoch 10/10\n13329/13329 [==============================] - 277s 21ms/step\n\n Phoneme Error Rate after epoch 9: 25.15241151783109%\n7775/7775 [==============================] - 906s 117ms/step - loss: 1.1552 - accuracy: 0.6415 - val_loss: 1.2767 - val_accuracy: 0.6063\nTraining time: 9722.65 seconds\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Save training performance metrics","metadata":{}},{"cell_type":"code","source":"\n# Collect training history metrics\ntraining_metrics = {\n    'epochs': list(range(1, len(history.history['accuracy']) + 1)),\n    'accuracy': history.history['accuracy'],\n    'loss': history.history['loss'],\n    'val_acc': history.history['val_accuracy'],\n    'val_loss': history.history['val_loss']\n}\n\n# Save the training metrics to a JSON file\nwith open('/kaggle/working/history_rnn.json', 'w') as file:\n    json.dump(training_metrics, file, indent=4)\n    \n# Save the PER metrics to a JSON file\nwith open('/kaggle/working/per_rnn.json', 'w') as file:\n    json.dump(performance_rnn, file, indent=4)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T22:48:41.774211Z","iopub.execute_input":"2023-07-28T22:48:41.774984Z","iopub.status.idle":"2023-07-28T22:48:41.784155Z","shell.execute_reply.started":"2023-07-28T22:48:41.774940Z","shell.execute_reply":"2023-07-28T22:48:41.783308Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Testing block","metadata":{}},{"cell_type":"code","source":"def compute_per(X, y, model, phoneme_mapping):\n    X = X.reshape(X.shape[0], 1, X.shape[1])\n    # Get the model predictions\n    predictions = model.predict(X)\n    \n    # Convert one-hot encoded vectors to phoneme sequences\n    reference_phonemes = [one_hot_to_phoneme(vec, phoneme_mapping) for vec in y]\n    predicted_phonemes = [one_hot_to_phoneme(vec, phoneme_mapping) for vec in predictions]\n\n    # Calculate PER\n    per = calculate_per(\" \".join(reference_phonemes), \" \".join(predicted_phonemes))\n    \n    return per\n\ndef one_hot_to_phoneme(one_hot_vector, phoneme_mapping):\n    index = np.argmax(one_hot_vector)\n    return phoneme_mapping.get(index-1, \"\")\n    \ndef calculate_per(reference, hypothesis):\n    distance = lev.distance(reference, hypothesis)\n    per = distance / len(reference)\n    return per * 100","metadata":{"execution":{"iopub.status.busy":"2023-07-28T22:48:41.785499Z","iopub.execute_input":"2023-07-28T22:48:41.785823Z","iopub.status.idle":"2023-07-28T22:48:41.813997Z","shell.execute_reply.started":"2023-07-28T22:48:41.785781Z","shell.execute_reply":"2023-07-28T22:48:41.812991Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Testing block# Testing","metadata":{}},{"cell_type":"code","source":"X_test = test_features\ny_test = test_labels\nX_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\ny_test = y_test.reshape(y_test.shape[0], 1, y_test.shape[1])\n\ntest_dataset = tf.data.Dataset.from_tensor_slices(\n    (X_test, y_test)\n)\n\ntest_dataset = (\n    test_dataset.map(preprocess_features, num_parallel_calls=tf.data.AUTOTUNE)\n    .padded_batch(batch_size)\n    .prefetch(buffer_size=tf.data.AUTOTUNE)\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T22:48:41.816355Z","iopub.execute_input":"2023-07-28T22:48:41.816930Z","iopub.status.idle":"2023-07-28T22:48:42.665733Z","shell.execute_reply.started":"2023-07-28T22:48:41.816897Z","shell.execute_reply":"2023-07-28T22:48:42.664795Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Save the model","metadata":{}},{"cell_type":"code","source":"# Save the model as an HDF5 file\nmodel.save(\"/kaggle/working/rnn_model.h5\")\n","metadata":{"execution":{"iopub.status.busy":"2023-07-28T22:48:42.667040Z","iopub.execute_input":"2023-07-28T22:48:42.667632Z","iopub.status.idle":"2023-07-28T22:48:43.519701Z","shell.execute_reply.started":"2023-07-28T22:48:42.667595Z","shell.execute_reply":"2023-07-28T22:48:43.518685Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Compute testing performance metrics","metadata":{}},{"cell_type":"code","source":"# Evaluate the model\nloss, accuracy = model.evaluate(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T22:48:43.521007Z","iopub.execute_input":"2023-07-28T22:48:43.521378Z","iopub.status.idle":"2023-07-28T22:51:06.074496Z","shell.execute_reply.started":"2023-07-28T22:48:43.521345Z","shell.execute_reply":"2023-07-28T22:51:06.073344Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"4059/4059 [==============================] - 121s 30ms/step - loss: 1.3606 - accuracy: 0.5856\n","output_type":"stream"}]},{"cell_type":"code","source":"# Compute PER on the test data\nper = compute_per(test_features, test_labels, model, phoneme39_to_label)\n\nprint(f'Loss: {loss}, Accuracy: {accuracy}, Phoneme Error Rate: {per}%')","metadata":{"execution":{"iopub.status.busy":"2023-07-28T22:51:06.076075Z","iopub.execute_input":"2023-07-28T22:51:06.077567Z","iopub.status.idle":"2023-07-28T22:58:38.934022Z","shell.execute_reply.started":"2023-07-28T22:51:06.077522Z","shell.execute_reply":"2023-07-28T22:58:38.933023Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"16236/16236 [==============================] - 340s 21ms/step\nLoss: 1.3605653047561646, Accuracy: 0.5855926275253296, Phoneme Error Rate: 25.233395946059606%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}