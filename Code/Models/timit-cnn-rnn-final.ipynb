{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Libraries","metadata":{"id":"uzVdcLLKNtsp"}},{"cell_type":"code","source":"# TensorFlow and Keras Imports\nimport tensorflow as tf\nfrom tensorflow.keras import regularizers as rg\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n# Garbage Collection and Pickle Imports\nimport gc\nimport pickle as pkl\n\n# Visualization Imports\nimport matplotlib.pyplot as plt\n\n# Operating System and Numerical Computation Imports\nimport os\nimport numpy as np\n\n# Scikit-learn Import\nfrom sklearn.model_selection import train_test_split\n\n# Time-related Import\nimport time\n\n# Data Handling Imports\nimport pandas as pd\n","metadata":{"id":"bt5AOsNnNtsr","outputId":"d52ed9db-0aed-4571-dd90-eb6a4da01311","execution":{"iopub.status.busy":"2023-07-29T00:22:57.601390Z","iopub.execute_input":"2023-07-29T00:22:57.601785Z","iopub.status.idle":"2023-07-29T00:22:57.610782Z","shell.execute_reply.started":"2023-07-29T00:22:57.601750Z","shell.execute_reply":"2023-07-29T00:22:57.608438Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Load Training Data","metadata":{"id":"bj3OtJPoNtss"}},{"cell_type":"code","source":"features_path = \"/kaggle/input/timitpreprocessed/features.pkl\"\nlabels_path = \"/kaggle/input/timitpreprocessed/labels.pkl\"\n\nwith open(features_path, 'rb') as pickle_file:\n    features = pkl.load(pickle_file)\n\nwith open(labels_path, 'rb') as pickle_file:\n    labels = pkl.load(pickle_file)","metadata":{"id":"1BNCfxrFNtss","execution":{"iopub.status.busy":"2023-07-29T00:22:57.614420Z","iopub.execute_input":"2023-07-29T00:22:57.619219Z","iopub.status.idle":"2023-07-29T00:23:07.408781Z","shell.execute_reply.started":"2023-07-29T00:22:57.619138Z","shell.execute_reply":"2023-07-29T00:23:07.407780Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Load Testing Data","metadata":{"id":"HU_KpeKbNtss"}},{"cell_type":"code","source":"test_features_path = \"/kaggle/input/timitpreprocessed/test_features.pkl\"\ntest_labels_path = \"/kaggle/input/timitpreprocessed/test_labels.pkl\"\n\nwith open(test_features_path, 'rb') as pickle_file:\n    test_features = pkl.load(pickle_file)\n\nwith open(test_labels_path, 'rb') as pickle_file:\n    test_labels = pkl.load(pickle_file)","metadata":{"id":"APuqYeDqNtst","execution":{"iopub.status.busy":"2023-07-29T00:23:07.410234Z","iopub.execute_input":"2023-07-29T00:23:07.410617Z","iopub.status.idle":"2023-07-29T00:23:11.316736Z","shell.execute_reply.started":"2023-07-29T00:23:07.410579Z","shell.execute_reply":"2023-07-29T00:23:11.315639Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Create mapping functions for Phonemes","metadata":{"id":"YhFqHrEdNtst"}},{"cell_type":"code","source":"map_phonemes_61_to_39 = {\n            'iy':'iy',  'ih':'ih',   'eh':'eh',  'ae':'ae',    'ix':'ih',  'ax':'ah',   'ah':'ah',  'uw':'uw',\n            'ux':'uw',  'uh':'uh',   'ao':'aa',  'aa':'aa',    'ey':'ey',  'ay':'ay',   'oy':'oy',  'aw':'aw',\n            'ow':'ow',  'l':'l',     'el':'l',  'r':'r',      'y':'y',    'w':'w',     'er':'er',  'axr':'er',\n            'm':'m',    'em':'m',     'n':'n',    'nx':'n',     'en':'n',  'ng':'ng',   'eng':'ng', 'ch':'ch',\n            'jh':'jh',  'dh':'dh',   'b':'b',    'd':'d',      'dx':'dx',  'g':'g',     'p':'p',    't':'t',\n            'k':'k',    'z':'z',     'zh':'sh',  'v':'v',      'f':'f',    'th':'th',   's':'s',    'sh':'sh',\n            'hh':'hh',  'hv':'hh',   'pcl':'h#', 'tcl':'h#', 'kcl':'h#', 'qcl':'h#','bcl':'h#','dcl':'h#',\n            'gcl':'h#','h#':'h#',  '#h':'h#',  'pau':'h#', 'epi': 'h#','nx':'n',   'ax-h':'ah','q':'h#'\n        }\n\nphonemes_list_61 = list(map_phonemes_61_to_39.keys())\nphonemes_list_39 = list(set(map_phonemes_61_to_39.values()))\n\nlabel_to_phoneme39 = {}\nphoneme39_to_label = {}\nfor index,phoneme in enumerate(phonemes_list_39):\n    label_to_phoneme39[phoneme] = index + 1\n    phoneme39_to_label[index + 1] = phoneme\n\nmap_phonemes_39_to_61 = {}\n\nfor phoneme61,phoneme39 in map_phonemes_61_to_39.items():\n    if not phoneme39 in map_phonemes_39_to_61:\n        map_phonemes_39_to_61[phoneme39] = []\n    map_phonemes_39_to_61[phoneme39].append(phoneme61)","metadata":{"id":"hhqTfjLNNtst","execution":{"iopub.status.busy":"2023-07-29T00:23:11.320736Z","iopub.execute_input":"2023-07-29T00:23:11.321046Z","iopub.status.idle":"2023-07-29T00:23:11.335601Z","shell.execute_reply.started":"2023-07-29T00:23:11.321018Z","shell.execute_reply":"2023-07-29T00:23:11.333477Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Build CNN+RNN Model","metadata":{"id":"QLs4peswNtsu"}},{"cell_type":"code","source":"from tensorflow.keras.layers import Flatten\n\ndef build_model(input_dim, output_dim, rnn_layers=5, rnn_units=128):\n    \"\"\"Model similar to DeepSpeech2.\"\"\"\n    # Model's input\n\n    input_mfcc = layers.Input((None, input_dim), name=\"input\")\n    # Convolution layer 1\n    x = layers.Conv1D(\n        filters=32,\n        kernel_size=11,\n\n        padding=\"same\",\n        use_bias=False,\n        name=\"conv_1\",\n    )(input_mfcc)\n    x = layers.BatchNormalization(name=\"conv_1_bn\")(x)\n    x = layers.ReLU(name=\"conv_1_relu\")(x)\n\n    # Convolution layer 2\n    x = layers.Conv1D(\n        filters=32,\n        kernel_size=11,\n\n        padding=\"same\",\n        use_bias=False,\n        name=\"conv_2\",\n    )(x)\n    x = layers.BatchNormalization(name=\"conv_2_bn\")(x)\n    x = layers.ReLU(name=\"conv_2_relu\")(x)\n\n    # Model's input\n    #input_mfcc = layers.Input((None, input_dim), name=\"input\")  # None represents variable sequence length, input_dim should be defined according to your data\n\n    # RNN layers\n    x = layers.LSTM(128, return_sequences=True) (x)\n    x = layers.LSTM(64, return_sequences=True) (x)\n\n    #x = layers.GlobalAveragePooling1D()(x)\n\n    # Dense layer\n    output = layers.TimeDistributed(layers.Dense(output_dim, activation='softmax'))(x)\n\n    model = keras.Model(input_mfcc, output, name=\"CNN_RNN\")\n    # Optimizer\n    opt = keras.optimizers.Adam(learning_rate=1e-4)\n    # Compile the model and return\n    model.compile(optimizer=opt, loss='categorical_crossentropy', run_eagerly=True, metrics=['accuracy'])\n    return model\n\nn_mels = 64\nfft_length =  384\n# Get the model\nmodel = build_model(\n    input_dim= n_mels*3,\n    output_dim=len(phoneme39_to_label),\n    rnn_units=512,\n)\nmodel.summary(line_length=110)\n\n\ndef preprocess_features(features, labels):\n    # Add your preprocessing steps here if any\n    return features, labels","metadata":{"id":"q1j0T5hlNtsu","outputId":"236e65ec-38d1-431c-d0cc-d1894fd04298","execution":{"iopub.status.busy":"2023-07-29T00:23:11.337629Z","iopub.execute_input":"2023-07-29T00:23:11.338084Z","iopub.status.idle":"2023-07-29T00:23:16.604630Z","shell.execute_reply.started":"2023-07-29T00:23:11.338047Z","shell.execute_reply":"2023-07-29T00:23:16.603891Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Model: \"CNN_RNN\"\n______________________________________________________________________________________________________________\n Layer (type)                                    Output Shape                                Param #          \n==============================================================================================================\n input (InputLayer)                              [(None, None, 192)]                         0                \n                                                                                                              \n conv_1 (Conv1D)                                 (None, None, 32)                            67584            \n                                                                                                              \n conv_1_bn (BatchNormalization)                  (None, None, 32)                            128              \n                                                                                                              \n conv_1_relu (ReLU)                              (None, None, 32)                            0                \n                                                                                                              \n conv_2 (Conv1D)                                 (None, None, 32)                            11264            \n                                                                                                              \n conv_2_bn (BatchNormalization)                  (None, None, 32)                            128              \n                                                                                                              \n conv_2_relu (ReLU)                              (None, None, 32)                            0                \n                                                                                                              \n lstm (LSTM)                                     (None, None, 128)                           82432            \n                                                                                                              \n lstm_1 (LSTM)                                   (None, None, 64)                            49408            \n                                                                                                              \n time_distributed (TimeDistributed)              (None, None, 39)                            2535             \n                                                                                                              \n==============================================================================================================\nTotal params: 213,479\nTrainable params: 213,351\nNon-trainable params: 128\n______________________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Create callback class to computer Phoneme Error Rate","metadata":{"id":"NJKmeGFrNtsu"}},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.callbacks import Callback\nimport Levenshtein as lev\n\nperformance_cnn_rnn = {}\n\nclass PERCallback(Callback):\n    def __init__(self, X_val, y_val, phoneme_mapping):\n        self.X_val = X_val\n        self.X_val = self.X_val.reshape(self.X_val.shape[0], 1, self.X_val.shape[1])\n        self.y_val = y_val\n        self.phoneme_mapping = phoneme_mapping\n\n    def on_epoch_end(self, epoch, logs=None):\n        gc.collect()\n        # Get the model predictions\n        predictions = self.model.predict(self.X_val)\n\n        # Convert one-hot encoded vectors to phoneme sequences\n        reference_phonemes = [self.one_hot_to_phoneme(vec) for vec in self.y_val]\n        predicted_phonemes = [self.one_hot_to_phoneme(vec) for vec in predictions]\n\n        # Calculate PER\n        per = self.calculate_per(\" \".join(reference_phonemes), \" \".join(predicted_phonemes))\n        performance_cnn_rnn[epoch] = per\n        # Print PER\n        print(f'\\n Phoneme Error Rate after epoch {epoch}: {per}%')\n\n    def one_hot_to_phoneme(self, one_hot_vector):\n        index = np.argmax(one_hot_vector)\n        return self.phoneme_mapping.get(index-1, \"\")\n\n    import Levenshtein as lev\n\n    def calculate_per(self, reference, hypothesis):\n        distance = lev.distance(reference, hypothesis)\n        per = distance / len(reference)\n        return per * 100","metadata":{"id":"kZhGumStNtsu","execution":{"iopub.status.busy":"2023-07-29T00:23:16.605672Z","iopub.execute_input":"2023-07-29T00:23:16.605998Z","iopub.status.idle":"2023-07-29T00:23:16.727356Z","shell.execute_reply.started":"2023-07-29T00:23:16.605965Z","shell.execute_reply":"2023-07-29T00:23:16.726175Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Train the model","metadata":{"id":"dpT9J1miNtsv"}},{"cell_type":"code","source":"# Define the number of epochs.\nbatch_size = 128\n\n# This will split your data so that 70% is used for training and 30% for testing.\nX_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=0.3, random_state=42)\n\nX_train_reshaped = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\nX_val_reshaped = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n\ny_train_reshaped = y_train.reshape(y_train.shape[0], 1, y_train.shape[1])\ny_val_reshaped = y_val.reshape(y_val.shape[0], 1, y_val.shape[1])\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices(\n    (X_train_reshaped, y_train_reshaped)\n)\ntrain_dataset = (\n    train_dataset.map(preprocess_features, num_parallel_calls=tf.data.AUTOTUNE)\n    .padded_batch(batch_size)\n    .prefetch(buffer_size=tf.data.AUTOTUNE)\n)\n\nvalidation_dataset = tf.data.Dataset.from_tensor_slices(\n     (X_val_reshaped, y_val_reshaped)\n)\nvalidation_dataset = (\n    validation_dataset.map(preprocess_features, num_parallel_calls=tf.data.AUTOTUNE)\n    .padded_batch(batch_size)\n    .prefetch(buffer_size=tf.data.AUTOTUNE)\n)\n\nepochs = 10\n\n# Train the model\nstart_time = time.time()\n\nhistory = model.fit(\n    train_dataset,\n    validation_data=validation_dataset,\n    batch_size=batch_size,\n    epochs=epochs,\n    callbacks=[PERCallback(X_val, y_val, phoneme39_to_label)]\n)\n\nend_time = time.time()\n\n# Calculate the training time\ntraining_time = end_time - start_time\nprint(f\"Training time: {training_time:.2f} seconds\")","metadata":{"id":"RVGmhDbYNtsv","outputId":"f2248b6a-50fa-4f29-bb0e-eaabbee032ff","execution":{"iopub.status.busy":"2023-07-29T00:23:16.729447Z","iopub.execute_input":"2023-07-29T00:23:16.729862Z","iopub.status.idle":"2023-07-29T03:24:28.120675Z","shell.execute_reply.started":"2023-07-29T00:23:16.729820Z","shell.execute_reply":"2023-07-29T03:24:28.119576Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Epoch 1/10\n13329/13329 [==============================] - 290s 22ms/step\n\n Phoneme Error Rate after epoch 0: 37.07162163568799%\n7775/7775 [==============================] - 1060s 135ms/step - loss: 2.2670 - accuracy: 0.3869 - val_loss: 1.9896 - val_accuracy: 0.4384\nEpoch 2/10\n13329/13329 [==============================] - 277s 21ms/step\n\n Phoneme Error Rate after epoch 1: 34.565974691977004%\n7775/7775 [==============================] - 1056s 136ms/step - loss: 1.8272 - accuracy: 0.4737 - val_loss: 1.8327 - val_accuracy: 0.4719\nEpoch 3/10\n13329/13329 [==============================] - 285s 21ms/step\n\n Phoneme Error Rate after epoch 2: 33.38679569340305%\n7775/7775 [==============================] - 1052s 135ms/step - loss: 1.7254 - accuracy: 0.4960 - val_loss: 1.7581 - val_accuracy: 0.4901\nEpoch 4/10\n13329/13329 [==============================] - 290s 22ms/step\n\n Phoneme Error Rate after epoch 3: 33.92859001627291%\n7775/7775 [==============================] - 1056s 136ms/step - loss: 1.6658 - accuracy: 0.5095 - val_loss: 1.7882 - val_accuracy: 0.4806\nEpoch 5/10\n13329/13329 [==============================] - 286s 21ms/step\n\n Phoneme Error Rate after epoch 4: 32.95395008483427%\n7775/7775 [==============================] - 1064s 137ms/step - loss: 1.6245 - accuracy: 0.5191 - val_loss: 1.7184 - val_accuracy: 0.4957\nEpoch 6/10\n13329/13329 [==============================] - 283s 21ms/step\n\n Phoneme Error Rate after epoch 5: 32.493173356834795%\n7775/7775 [==============================] - 1049s 135ms/step - loss: 1.5935 - accuracy: 0.5262 - val_loss: 1.6820 - val_accuracy: 0.5031\nEpoch 7/10\n13329/13329 [==============================] - 283s 21ms/step\n\n Phoneme Error Rate after epoch 6: 33.54648883275678%\n7775/7775 [==============================] - 1051s 135ms/step - loss: 1.5685 - accuracy: 0.5320 - val_loss: 1.7169 - val_accuracy: 0.4879\nEpoch 8/10\n13329/13329 [==============================] - 282s 21ms/step\n\n Phoneme Error Rate after epoch 7: 32.33608249568889%\n7775/7775 [==============================] - 1071s 138ms/step - loss: 1.5473 - accuracy: 0.5369 - val_loss: 1.6638 - val_accuracy: 0.5069\nEpoch 9/10\n13329/13329 [==============================] - 282s 21ms/step\n\n Phoneme Error Rate after epoch 8: 31.737818735709155%\n7775/7775 [==============================] - 1045s 134ms/step - loss: 1.5287 - accuracy: 0.5414 - val_loss: 1.6307 - val_accuracy: 0.5164\nEpoch 10/10\n13329/13329 [==============================] - 282s 21ms/step\n\n Phoneme Error Rate after epoch 9: 31.736430853998314%\n7775/7775 [==============================] - 1023s 132ms/step - loss: 1.5127 - accuracy: 0.5453 - val_loss: 1.6304 - val_accuracy: 0.5164\nTraining time: 10868.34 seconds\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Save training performance metrics","metadata":{"id":"01v8h8vwNtsv"}},{"cell_type":"code","source":"import json\n# Collect training history metrics\ntraining_metrics = {\n    'epochs': list(range(1, len(history.history['accuracy']) + 1)),\n    'accuracy': history.history['accuracy'],\n    'loss': history.history['loss'],\n    'val_acc': history.history['val_accuracy'],\n    'val_loss': history.history['val_loss']\n}\n\n# Save the training metrics to a JSON file\nwith open('/kaggle/working/history_cnn_rnn.json', 'w') as file:\n    json.dump(training_metrics, file, indent=4)\n\n# Save the PER metrics to a JSON file\nwith open('/kaggle/working/per_cnn_rnn.json', 'w') as file:\n    json.dump(performance_cnn_rnn, file, indent=4)","metadata":{"id":"-3VMHshUNtsv","execution":{"iopub.status.busy":"2023-07-29T03:24:28.122481Z","iopub.execute_input":"2023-07-29T03:24:28.122874Z","iopub.status.idle":"2023-07-29T03:24:28.130552Z","shell.execute_reply.started":"2023-07-29T03:24:28.122838Z","shell.execute_reply":"2023-07-29T03:24:28.129461Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Save the model","metadata":{"id":"hF7Xd_h3Ntsv"}},{"cell_type":"code","source":"# Save the model as an HDF5 file\nmodel.save(\"/kaggle/working/cnn_rnn_model.h5\")","metadata":{"id":"aMgKrTomNtsv","execution":{"iopub.status.busy":"2023-07-29T03:24:28.132293Z","iopub.execute_input":"2023-07-29T03:24:28.132978Z","iopub.status.idle":"2023-07-29T03:24:28.237744Z","shell.execute_reply.started":"2023-07-29T03:24:28.132945Z","shell.execute_reply":"2023-07-29T03:24:28.236763Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Testing block","metadata":{"id":"aaOK0w6zNtsv"}},{"cell_type":"code","source":"def compute_per(X, y, model, phoneme_mapping):\n    X = X.reshape(X.shape[0], 1, X.shape[1])\n    # Get the model predictions\n    predictions = model.predict(X)\n\n    # Convert one-hot encoded vectors to phoneme sequences\n    reference_phonemes = [one_hot_to_phoneme(vec, phoneme_mapping) for vec in y]\n    predicted_phonemes = [one_hot_to_phoneme(vec, phoneme_mapping) for vec in predictions]\n\n    # Calculate PER\n    per = calculate_per(\" \".join(reference_phonemes), \" \".join(predicted_phonemes))\n\n    return per\n\ndef one_hot_to_phoneme(one_hot_vector, phoneme_mapping):\n    index = np.argmax(one_hot_vector)\n    return phoneme_mapping.get(index-1, \"\")\n\ndef calculate_per(reference, hypothesis):\n    distance = lev.distance(reference, hypothesis)\n    per = distance / len(reference)\n    return per * 100","metadata":{"id":"NmBJu3_ONtsv","execution":{"iopub.status.busy":"2023-07-29T03:24:28.240949Z","iopub.execute_input":"2023-07-29T03:24:28.241315Z","iopub.status.idle":"2023-07-29T03:24:28.249383Z","shell.execute_reply.started":"2023-07-29T03:24:28.241283Z","shell.execute_reply":"2023-07-29T03:24:28.248398Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Testing","metadata":{"id":"5PA8Q2DoNtsv"}},{"cell_type":"code","source":"X_test = test_features\ny_test = test_labels\nX_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\ny_test = y_test.reshape(y_test.shape[0], 1, y_test.shape[1])\n\ntest_dataset = tf.data.Dataset.from_tensor_slices(\n    (X_test, y_test)\n)\n\ntest_dataset = (\n    test_dataset.map(preprocess_features, num_parallel_calls=tf.data.AUTOTUNE)\n    .padded_batch(batch_size)\n    .prefetch(buffer_size=tf.data.AUTOTUNE)\n)","metadata":{"id":"d-7BD-UsNtsv","execution":{"iopub.status.busy":"2023-07-29T03:24:28.250830Z","iopub.execute_input":"2023-07-29T03:24:28.251439Z","iopub.status.idle":"2023-07-29T03:24:29.098280Z","shell.execute_reply.started":"2023-07-29T03:24:28.251406Z","shell.execute_reply":"2023-07-29T03:24:29.097210Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Compute testing performance metrics","metadata":{"id":"WRDxAk7ANtsv"}},{"cell_type":"code","source":"# Evaluate the model\nloss, accuracy = model.evaluate(test_dataset)","metadata":{"id":"nGl14iEoNtsv","outputId":"8d933aff-45c0-430c-fe62-fbaa38789feb","execution":{"iopub.status.busy":"2023-07-29T03:24:29.099610Z","iopub.execute_input":"2023-07-29T03:24:29.099960Z","iopub.status.idle":"2023-07-29T03:26:51.538776Z","shell.execute_reply.started":"2023-07-29T03:24:29.099922Z","shell.execute_reply":"2023-07-29T03:26:51.537545Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"4059/4059 [==============================] - 124s 30ms/step - loss: 1.6501 - accuracy: 0.5115\n","output_type":"stream"}]},{"cell_type":"code","source":"# Compute PER on the test data\nper = compute_per(test_features, test_labels, model, phoneme39_to_label)\n\nprint(f'Loss: {loss}, Accuracy: {accuracy}, Phoneme Error Rate: {per}%')","metadata":{"id":"exXLyfySNtsv","outputId":"5d488806-d4b7-4050-9f01-f2fd7b3f7935","execution":{"iopub.status.busy":"2023-07-29T03:26:51.540640Z","iopub.execute_input":"2023-07-29T03:26:51.541218Z","iopub.status.idle":"2023-07-29T03:34:07.097057Z","shell.execute_reply.started":"2023-07-29T03:26:51.541176Z","shell.execute_reply":"2023-07-29T03:34:07.095153Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"16236/16236 [==============================] - 344s 21ms/step\nLoss: 1.6500742435455322, Accuracy: 0.5115134119987488, Phoneme Error Rate: 30.411115028866735%\n","output_type":"stream"}]}]}